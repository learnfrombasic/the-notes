{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "\n",
    "Link: [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "__all__ = [\"ResNet\", \"resnet18\", \"resnet34\", \"resnet50\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        padding = 2 - stride\n",
    "\n",
    "        if dilation > 1:\n",
    "            padding = dilation\n",
    "\n",
    "        dd = dilation\n",
    "        pad = padding\n",
    "        if downsample is not None and dilation > 1:\n",
    "            dd = dilation // 2\n",
    "            pad = dd\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes,\n",
    "            planes,\n",
    "            stride=stride,\n",
    "            dilation=dd,\n",
    "            bias=False,\n",
    "            kernel_size=3,\n",
    "            padding=pad,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        padding = 2 - stride\n",
    "        if downsample is not None and dilation > 1:\n",
    "            dilation = dilation // 2\n",
    "            padding = dilation\n",
    "\n",
    "        assert stride == 1 or dilation == 1, (\n",
    "            \"stride and dilation must have one equals to zero at least\"\n",
    "        )\n",
    "\n",
    "        if dilation > 1:\n",
    "            padding = dilation\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, used_layers):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3,\n",
    "            64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=0,  # 3\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "\n",
    "        self.feature_size = 128 * block.expansion\n",
    "        self.used_layers = used_layers\n",
    "        layer3 = True if 3 in used_layers else False\n",
    "        layer4 = True if 4 in used_layers else False\n",
    "\n",
    "        if layer3:\n",
    "            self.layer3 = self._make_layer(\n",
    "                block, 256, layers[2], stride=1, dilation=2\n",
    "            )  # 15x15, 7x7\n",
    "            self.feature_size = (256 + 128) * block.expansion\n",
    "        else:\n",
    "            self.layer3 = lambda x: x  # identity\n",
    "\n",
    "        if layer4:\n",
    "            self.layer4 = self._make_layer(\n",
    "                block, 512, layers[3], stride=1, dilation=4\n",
    "            )  # 7x7, 3x3\n",
    "            self.feature_size = 512 * block.expansion\n",
    "        else:\n",
    "            self.layer4 = lambda x: x  # identity\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        dd = dilation\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if stride == 1 and dilation == 1:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(planes * block.expansion),\n",
    "                )\n",
    "            else:\n",
    "                if dilation > 1:\n",
    "                    dd = dilation // 2\n",
    "                    padding = dd\n",
    "                else:\n",
    "                    dd = 1\n",
    "                    padding = 0\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=3,\n",
    "                        stride=stride,\n",
    "                        bias=False,\n",
    "                        padding=padding,\n",
    "                        dilation=dd,\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(planes * block.expansion),\n",
    "                )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, downsample, dilation=dilation)\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x_ = self.relu(x)\n",
    "        x = self.maxpool(x_)\n",
    "\n",
    "        p1 = self.layer1(x)\n",
    "        p2 = self.layer2(p1)\n",
    "        p3 = self.layer3(p2)\n",
    "        p4 = self.layer4(p3)\n",
    "        out = [x_, p1, p2, p3, p4]\n",
    "        out = [out[i] for i in self.used_layers]\n",
    "        if len(out) == 1:\n",
    "            return out[0]\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "*************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[[3.8487e-01, 0.0000e+00, 6.6706e-01,  ..., 6.3388e-01,\n",
       "            3.2146e-01, 1.7131e+00],\n",
       "           [0.0000e+00, 2.2644e+00, 0.0000e+00,  ..., 1.4887e-01,\n",
       "            0.0000e+00, 1.7222e+00],\n",
       "           [4.3826e-01, 9.1411e-01, 1.5816e-01,  ..., 6.8510e-01,\n",
       "            8.5655e-01, 4.3165e-01],\n",
       "           ...,\n",
       "           [8.6335e-01, 0.0000e+00, 2.4983e-04,  ..., 4.2188e-01,\n",
       "            2.0350e+00, 9.2043e-01],\n",
       "           [7.6528e-01, 0.0000e+00, 9.7877e-01,  ..., 1.5061e+00,\n",
       "            0.0000e+00, 1.4574e-02],\n",
       "           [0.0000e+00, 3.4922e+00, 8.5980e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.2745e+00]],\n",
       " \n",
       "          [[1.8079e+00, 2.5692e+00, 1.2763e+00,  ..., 3.0807e+00,\n",
       "            8.6071e-01, 4.3631e+00],\n",
       "           [1.5807e+00, 2.7857e+00, 0.0000e+00,  ..., 8.3089e-03,\n",
       "            1.8678e+00, 4.9323e+00],\n",
       "           [2.3877e-01, 0.0000e+00, 1.2513e+00,  ..., 1.4874e+00,\n",
       "            1.2206e+00, 2.9585e+00],\n",
       "           ...,\n",
       "           [1.6501e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.1166e-01],\n",
       "           [2.6925e+00, 0.0000e+00, 2.6241e+00,  ..., 3.6796e+00,\n",
       "            2.3162e+00, 2.6617e+00],\n",
       "           [7.8766e-01, 2.0832e+00, 2.3994e+00,  ..., 1.2255e+00,\n",
       "            2.7404e+00, 1.3941e+00]],\n",
       " \n",
       "          [[0.0000e+00, 1.2448e+00, 1.7215e+00,  ..., 2.5910e+00,\n",
       "            3.5930e+00, 0.0000e+00],\n",
       "           [6.6489e-01, 3.9021e-01, 1.8180e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.0223e+00, 2.3362e+00, 1.1758e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [3.9055e-01, 1.9576e+00, 4.2488e+00,  ..., 2.8976e+00,\n",
       "            1.0088e+00, 6.9816e-01],\n",
       "           [4.0271e+00, 1.1069e+00, 0.0000e+00,  ..., 6.1007e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [5.3060e-01, 0.0000e+00, 0.0000e+00,  ..., 9.1453e-01,\n",
       "            8.0743e-02, 7.3022e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000e+00, 1.0433e+00, 0.0000e+00,  ..., 5.4850e-01,\n",
       "            9.5293e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 1.0350e+00, 0.0000e+00,  ..., 1.4072e+00,\n",
       "            5.2289e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2555e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [7.4642e-01, 1.9422e+00, 2.0447e-01,  ..., 1.6116e+00,\n",
       "            0.0000e+00, 3.0400e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.5512e-01,\n",
       "            0.0000e+00, 5.8433e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 7.9153e-01,  ..., 1.8163e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 2.7310e-01,  ..., 0.0000e+00,\n",
       "            1.9152e+00, 4.9682e-01],\n",
       "           [1.6163e+00, 5.1744e-02, 2.2632e-01,  ..., 0.0000e+00,\n",
       "            1.6583e+00, 8.0540e-01],\n",
       "           [2.5703e+00, 6.8687e-01, 2.9847e-01,  ..., 8.2206e-01,\n",
       "            1.3118e+00, 7.8094e-01],\n",
       "           ...,\n",
       "           [1.1681e+00, 3.2752e+00, 7.5158e-01,  ..., 9.3635e-02,\n",
       "            0.0000e+00, 8.1604e-02],\n",
       "           [2.6680e-01, 4.3687e+00, 2.8677e-01,  ..., 2.6444e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [4.6254e+00, 2.5297e-01, 1.0965e+00,  ..., 2.5547e+00,\n",
       "            1.7469e+00, 6.1031e-01]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.6478e-01,\n",
       "            8.2955e-01, 0.0000e+00],\n",
       "           [0.0000e+00, 1.2269e+00, 5.1421e-02,  ..., 8.9370e-01,\n",
       "            8.2529e-01, 2.1817e+00],\n",
       "           [1.4765e+00, 0.0000e+00, 4.5104e-01,  ..., 2.9908e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1847e+00,\n",
       "            6.5255e-01, 9.6012e-01],\n",
       "           [0.0000e+00, 2.1847e+00, 1.7004e+00,  ..., 5.5103e-01,\n",
       "            1.2677e+00, 2.1826e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3908e+00,\n",
       "            1.6400e+00, 1.2087e+00]]]], device='cuda:0',\n",
       "        grad_fn=<ReluBackward0>),\n",
       " tensor([[[[9.9986e-01, 1.6780e+00, 2.7404e+00,  ..., 0.0000e+00,\n",
       "            1.6315e+00, 1.3258e+00],\n",
       "           [1.3510e+00, 0.0000e+00, 8.5698e-02,  ..., 0.0000e+00,\n",
       "            1.1708e+00, 2.1390e+00],\n",
       "           [1.5804e+00, 7.3542e-01, 2.0864e+00,  ..., 3.6722e+00,\n",
       "            1.3495e+00, 1.5808e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6476e-01,\n",
       "            5.0555e+00, 4.5620e-01],\n",
       "           [0.0000e+00, 4.2697e-01, 1.4264e+00,  ..., 8.4873e-01,\n",
       "            0.0000e+00, 2.8806e+00],\n",
       "           [3.5844e-03, 0.0000e+00, 1.1055e+00,  ..., 9.6697e-01,\n",
       "            1.8210e+00, 7.2719e-01]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 3.7913e-01],\n",
       "           [0.0000e+00, 7.0268e-01, 0.0000e+00,  ..., 1.3798e+00,\n",
       "            0.0000e+00, 6.4992e-01],\n",
       "           [1.3511e+00, 2.1669e+00, 0.0000e+00,  ..., 3.8396e+00,\n",
       "            4.9642e-01, 8.9904e-01],\n",
       "           ...,\n",
       "           [2.4528e+00, 0.0000e+00, 2.8491e-01,  ..., 8.3821e-02,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.0916e+00, 6.8411e-02, 1.3104e+00,  ..., 1.3598e+00,\n",
       "            0.0000e+00, 8.9156e-02],\n",
       "           [4.1225e+00, 1.9772e+00, 0.0000e+00,  ..., 1.0648e+00,\n",
       "            0.0000e+00, 2.4323e+00]],\n",
       " \n",
       "          [[2.1594e+00, 1.8530e+00, 1.7770e+00,  ..., 4.8225e-01,\n",
       "            6.6601e-01, 1.6404e+00],\n",
       "           [5.9850e-01, 1.3564e+00, 1.4850e-01,  ..., 1.7328e+00,\n",
       "            6.7380e-01, 1.5525e+00],\n",
       "           [7.0141e-01, 1.8649e+00, 1.2596e+00,  ..., 0.0000e+00,\n",
       "            1.1312e+00, 7.6489e-01],\n",
       "           ...,\n",
       "           [3.2741e+00, 1.5607e+00, 2.4216e-01,  ..., 1.2931e-01,\n",
       "            2.9697e+00, 5.2367e-01],\n",
       "           [1.1425e+00, 5.6200e-01, 3.4429e-01,  ..., 8.3271e-01,\n",
       "            8.2783e-01, 6.3792e-01],\n",
       "           [1.2650e+00, 3.2548e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            6.4246e-01, 1.3796e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000e+00, 1.3663e+00, 0.0000e+00,  ..., 3.6003e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.2421e-01, 0.0000e+00, 1.0613e+00,  ..., 4.3754e-01,\n",
       "            1.7548e-01, 0.0000e+00],\n",
       "           [1.2199e+00, 0.0000e+00, 7.3729e-01,  ..., 1.2677e+00,\n",
       "            1.1118e+00, 8.6037e-01],\n",
       "           ...,\n",
       "           [9.8745e-01, 1.8818e+00, 7.3690e-01,  ..., 1.2121e+00,\n",
       "            1.6177e+00, 2.5586e+00],\n",
       "           [1.6411e+00, 3.8008e-01, 3.4453e+00,  ..., 1.3036e+00,\n",
       "            1.5730e-01, 0.0000e+00],\n",
       "           [1.7137e+00, 0.0000e+00, 3.2340e+00,  ..., 0.0000e+00,\n",
       "            2.1836e+00, 3.0919e-01]],\n",
       " \n",
       "          [[0.0000e+00, 1.6879e-01, 0.0000e+00,  ..., 1.5879e+00,\n",
       "            4.9328e-01, 1.4983e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.2626e+00, 2.0869e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 2.5735e+00,  ..., 1.4230e+00,\n",
       "            1.2099e+00, 9.9733e-01],\n",
       "           ...,\n",
       "           [0.0000e+00, 1.0766e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            8.2058e-01, 1.0996e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 4.8064e+00,  ..., 9.5595e-03,\n",
       "            0.0000e+00, 1.4579e+00],\n",
       "           [4.8348e-01, 0.0000e+00, 0.0000e+00,  ..., 3.7169e-02,\n",
       "            2.7154e+00, 2.3507e+00]],\n",
       " \n",
       "          [[8.3393e-01, 1.0258e+00, 3.9870e+00,  ..., 2.9225e+00,\n",
       "            1.9462e+00, 3.9051e+00],\n",
       "           [1.6686e-01, 2.7724e+00, 1.4614e+00,  ..., 8.8957e-01,\n",
       "            2.4801e+00, 1.0705e+00],\n",
       "           [1.4975e+00, 2.7613e+00, 3.1799e+00,  ..., 6.5510e-01,\n",
       "            6.3843e-01, 1.8165e+00],\n",
       "           ...,\n",
       "           [2.1176e+00, 1.4133e+00, 1.3104e+00,  ..., 3.0701e-01,\n",
       "            1.3008e-01, 3.0125e+00],\n",
       "           [2.7716e+00, 2.4249e+00, 1.5166e-01,  ..., 3.6473e+00,\n",
       "            2.3763e+00, 0.0000e+00],\n",
       "           [2.6550e+00, 5.2720e-01, 1.0639e+00,  ..., 7.5003e-01,\n",
       "            8.7633e-01, 2.8413e+00]]]], device='cuda:0',\n",
       "        grad_fn=<ReluBackward0>),\n",
       " tensor([[[[9.8072e-01, 0.0000e+00, 3.0878e-02,  ..., 1.5260e+00,\n",
       "            4.0780e-01, 1.6093e+00],\n",
       "           [3.2156e-02, 0.0000e+00, 1.4952e+00,  ..., 5.6818e-01,\n",
       "            0.0000e+00, 7.9210e-01],\n",
       "           [9.9584e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            2.1179e+00, 2.1536e+00],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 1.2381e+00,  ..., 0.0000e+00,\n",
       "            7.7819e-01, 4.7206e-01],\n",
       "           [2.2659e+00, 0.0000e+00, 3.8462e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.4057e-01, 1.6630e+00, 8.0579e-01,  ..., 4.3792e-01,\n",
       "            0.0000e+00, 9.2066e-01]],\n",
       " \n",
       "          [[1.6563e+00, 2.1627e+00, 1.9454e+00,  ..., 2.4722e+00,\n",
       "            7.1886e-01, 7.5575e-01],\n",
       "           [9.4343e-01, 2.1410e+00, 1.6745e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [2.9001e+00, 3.3756e+00, 8.6751e-01,  ..., 9.9830e-01,\n",
       "            6.4343e-01, 1.3377e+00],\n",
       "           ...,\n",
       "           [1.0929e+00, 8.0303e-01, 3.6001e-01,  ..., 8.1537e-01,\n",
       "            2.2177e-01, 9.9777e-01],\n",
       "           [3.3855e+00, 1.7857e+00, 2.4193e+00,  ..., 1.3782e+00,\n",
       "            9.8912e-01, 1.5105e+00],\n",
       "           [2.5873e+00, 3.8574e+00, 1.1007e+00,  ..., 2.7458e-01,\n",
       "            8.9121e-01, 4.2095e-01]],\n",
       " \n",
       "          [[2.6463e-01, 0.0000e+00, 5.2828e-01,  ..., 8.4411e-01,\n",
       "            2.8737e-01, 4.8467e+00],\n",
       "           [4.4476e-01, 2.5118e-01, 0.0000e+00,  ..., 8.9977e-01,\n",
       "            2.4574e+00, 1.8640e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.5512e+00,\n",
       "            1.1656e+00, 8.9443e-01],\n",
       "           ...,\n",
       "           [8.1928e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            8.8918e-01, 3.1662e+00],\n",
       "           [9.4992e-01, 1.4239e+00, 0.0000e+00,  ..., 4.3356e-01,\n",
       "            2.3598e+00, 3.7389e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.5151e-01,\n",
       "            2.7978e+00, 3.0259e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000e+00, 5.7240e-01, 0.0000e+00,  ..., 5.9122e-01,\n",
       "            1.0860e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 8.9784e-01, 2.3956e+00,  ..., 2.1245e-01,\n",
       "            3.2301e-02, 0.0000e+00],\n",
       "           [7.9218e-01, 0.0000e+00, 3.6203e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 5.2651e-01],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4751e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [6.3383e-01, 0.0000e+00, 6.3496e-02,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.5774e-01, 0.0000e+00, 0.0000e+00,  ..., 2.8734e-02,\n",
       "            2.4332e+00, 0.0000e+00]],\n",
       " \n",
       "          [[2.4543e-01, 1.8168e+00, 1.3445e+00,  ..., 2.2099e+00,\n",
       "            1.0481e-01, 8.5180e-01],\n",
       "           [4.9605e-01, 1.9738e+00, 1.6405e+00,  ..., 9.4268e-01,\n",
       "            1.3254e+00, 1.9012e+00],\n",
       "           [0.0000e+00, 2.6802e-01, 0.0000e+00,  ..., 6.7355e-01,\n",
       "            0.0000e+00, 9.9462e-01],\n",
       "           ...,\n",
       "           [3.2715e+00, 1.2902e+00, 2.2070e+00,  ..., 1.4219e+00,\n",
       "            2.5828e-01, 0.0000e+00],\n",
       "           [1.5096e+00, 2.0940e+00, 8.0857e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 8.3192e-01],\n",
       "           [1.7186e+00, 1.9120e+00, 2.1631e+00,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "            1.8399e-03, 1.1373e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 1.8974e+00,  ..., 1.9539e+00,\n",
       "            7.9845e-01, 1.3978e+00],\n",
       "           [0.0000e+00, 1.0473e+00, 6.0782e-01,  ..., 0.0000e+00,\n",
       "            1.0575e+00, 9.7725e-01],\n",
       "           ...,\n",
       "           [0.0000e+00, 7.3544e-01, 2.8030e+00,  ..., 1.8636e+00,\n",
       "            1.6290e+00, 5.0211e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1784e+00,\n",
       "            2.2542e+00, 8.4716e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 8.0752e-01,  ..., 4.3906e+00,\n",
       "            1.4306e+00, 1.0359e+00]]]], device='cuda:0',\n",
       "        grad_fn=<ReluBackward0>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = resnet50(used_layers=[2, 3, 4])\n",
    "print(net)\n",
    "net = net.cuda()\n",
    "\n",
    "var = torch.FloatTensor(1, 3, 127, 127).cuda()\n",
    "# var = Variable(var)\n",
    "\n",
    "net(var)\n",
    "print(\"*************\")\n",
    "var = torch.FloatTensor(1, 3, 255, 255).cuda()\n",
    "# var = Variable(var)\n",
    "net(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the-notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
