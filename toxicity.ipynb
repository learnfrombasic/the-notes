{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/disk4tb/miniconda3/envs/the-notes/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "\u001b[32m25-03-09 12:14:13 - [TheNotes] - INFO - Login to Hugging Face Hub successful ðŸŽ‰\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from wordcloud import WordCloud\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from transformers import AdamW, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.hf_login import hf_login\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "hf_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The label function calculates a toxicity score by summing two columns: toxicity_ai and toxicity_human.\n",
    "If the total toxicity score is greater than 5.5, it assigns a label of 1; otherwise, it assigns 0. \n",
    "The .astype(int) ensures the result is stored as an integer (binary classification).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def label_annotations(annotated: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Annotations should be the annotated dataset\n",
    "    label = ((annotated.toxicity_ai + annotated.toxicity_human) > 5.5).astype(int)\n",
    "    labeled_annotations = pd.DataFrame()\n",
    "    labeled_annotations[\"text\"] = [i for i in annotated.text.tolist()]\n",
    "    labeled_annotations[\"label\"] = label\n",
    "    return labeled_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'generation', 'generation_method', 'group', 'prompt_label', 'roberta_prediction'],\n",
       "        num_rows: 250951\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxigen_train_ds = load_dataset(\"skg/toxigen-data\", name=\"train\")\n",
    "\n",
    "toxigen_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 940/940 [00:00<00:00, 272206.97 examples/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8960/8960 [00:00<00:00, 742604.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method'],\n",
       "        num_rows: 940\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method'],\n",
       "        num_rows: 8960\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxigen_annotated = load_dataset(\"skg/toxigen-data\", name=\"annotated\")\n",
    "\n",
    "toxigen_annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "      <th>generation_method</th>\n",
       "      <th>group</th>\n",
       "      <th>prompt_label</th>\n",
       "      <th>roberta_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- the vast majority of african-americans are p...</td>\n",
       "      <td>if youre white, you should be proud to be whit...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- black people from the middle ages have alway...</td>\n",
       "      <td>the best thing that could have happened to the...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- many african americans are so savage they lo...</td>\n",
       "      <td>theres no hope for the future because theres n...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- the vast majority of african-americans are p...</td>\n",
       "      <td>if youre white, you should be proud of it.</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- whether a scientist or janitor, black people...</td>\n",
       "      <td>no matter how much money or power you have, if...</td>\n",
       "      <td>ALICE</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  - the vast majority of african-americans are p...   \n",
       "1  - black people from the middle ages have alway...   \n",
       "2  - many african americans are so savage they lo...   \n",
       "3  - the vast majority of african-americans are p...   \n",
       "4  - whether a scientist or janitor, black people...   \n",
       "\n",
       "                                          generation generation_method  group  \\\n",
       "0  if youre white, you should be proud to be whit...             ALICE  black   \n",
       "1  the best thing that could have happened to the...             ALICE  black   \n",
       "2  theres no hope for the future because theres n...             ALICE  black   \n",
       "3         if youre white, you should be proud of it.             ALICE  black   \n",
       "4  no matter how much money or power you have, if...             ALICE  black   \n",
       "\n",
       "   prompt_label  roberta_prediction  \n",
       "0             1               0.001  \n",
       "1             1               0.044  \n",
       "2             1               0.014  \n",
       "3             1               0.002  \n",
       "4             1               0.328  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TG = pd.DataFrame(\n",
    "    toxigen_train_ds[\"train\"]\n",
    ")  # Toxigen is stored in the train split of a huggingface dataset\n",
    "TG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black' 'asian' 'native_american' 'muslim' 'latino' 'jewish' 'chinese'\n",
      " 'lgbtq' 'mental_dis' 'physical_dis' 'mexican' 'women' 'middle_east']\n"
     ]
    }
   ],
   "source": [
    "# ToxiGen contains data for 13 groups\n",
    "print(TG.group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "      <th>generation_method</th>\n",
       "      <th>group</th>\n",
       "      <th>prompt_label</th>\n",
       "      <th>roberta_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57948</th>\n",
       "      <td>- african american women have a different inve...</td>\n",
       "      <td>a black transgender man, regularly talks need...</td>\n",
       "      <td>top-k</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57949</th>\n",
       "      <td>- african american women have a different inve...</td>\n",
       "      <td>black girls don't have a seat at the table of...</td>\n",
       "      <td>top-k</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57950</th>\n",
       "      <td>- african american women have a different inve...</td>\n",
       "      <td>by and large, white americans have been uniqu...</td>\n",
       "      <td>top-k</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57951</th>\n",
       "      <td>- african american women have a different inve...</td>\n",
       "      <td>it seems that there's still a deep discomfort...</td>\n",
       "      <td>top-k</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57952</th>\n",
       "      <td>- african american women have a different inve...</td>\n",
       "      <td>Black womens equality and role within society...</td>\n",
       "      <td>top-k</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "57948  - african american women have a different inve...   \n",
       "57949  - african american women have a different inve...   \n",
       "57950  - african american women have a different inve...   \n",
       "57951  - african american women have a different inve...   \n",
       "57952  - african american women have a different inve...   \n",
       "\n",
       "                                              generation generation_method  \\\n",
       "57948   a black transgender man, regularly talks need...             top-k   \n",
       "57949   black girls don't have a seat at the table of...             top-k   \n",
       "57950   by and large, white americans have been uniqu...             top-k   \n",
       "57951   it seems that there's still a deep discomfort...             top-k   \n",
       "57952   Black womens equality and role within society...             top-k   \n",
       "\n",
       "       group  prompt_label  roberta_prediction  \n",
       "57948  black             0               0.001  \n",
       "57949  black             0               0.001  \n",
       "57950  black             0               0.001  \n",
       "57951  black             0               0.001  \n",
       "57952  black             0               0.001  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of loading only neutral examples\n",
    "neutral_examples = TG[TG.prompt_label == 0.0]\n",
    "neutral_examples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore human annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_eval_big = pd.DataFrame(toxigen_annotated[\"train\"])\n",
    "human_eval_small = pd.DataFrame(toxigen_annotated[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8960, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_group</th>\n",
       "      <th>factual?</th>\n",
       "      <th>ingroup_effect</th>\n",
       "      <th>lewd</th>\n",
       "      <th>framing</th>\n",
       "      <th>predicted_group</th>\n",
       "      <th>stereotyping</th>\n",
       "      <th>intent</th>\n",
       "      <th>toxicity_ai</th>\n",
       "      <th>toxicity_human</th>\n",
       "      <th>predicted_author</th>\n",
       "      <th>actual_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asians are trying to take over the world with ...</td>\n",
       "      <td>asian</td>\n",
       "      <td>opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>the text directly references asian</td>\n",
       "      <td>uses positive stereotyping</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have never seen a hotter lineup in my life t...</td>\n",
       "      <td>mexican</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td></td>\n",
       "      <td>['it is unclear who is referenced', 'it is unc...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muslims deseve to die</td>\n",
       "      <td>muslim</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>moral</td>\n",
       "      <td>the text directly references muslim</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people who are deaf or hard of hearing should ...</td>\n",
       "      <td>physical_dis</td>\n",
       "      <td>opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>['the text indirectly references physical_dis'...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>human</td>\n",
       "      <td>cbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jews were all bad people because they're in th...</td>\n",
       "      <td>jewish</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>moral</td>\n",
       "      <td>the text directly references jewish</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target_group  \\\n",
       "0  asians are trying to take over the world with ...         asian   \n",
       "1  i have never seen a hotter lineup in my life t...       mexican   \n",
       "2                              muslims deseve to die        muslim   \n",
       "3  people who are deaf or hard of hearing should ...  physical_dis   \n",
       "4  Jews were all bad people because they're in th...        jewish   \n",
       "\n",
       "                      factual?                 ingroup_effect  \\\n",
       "0                      opinion  doesn't use in-group language   \n",
       "1  neither factual nor opinion  doesn't use in-group language   \n",
       "2  neither factual nor opinion  doesn't use in-group language   \n",
       "3                      opinion  doesn't use in-group language   \n",
       "4                 disagreement  doesn't use in-group language   \n",
       "\n",
       "                           lewd       framing  \\\n",
       "0  doesn't contain lewd content  disagreement   \n",
       "1  doesn't contain lewd content                 \n",
       "2  doesn't contain lewd content         moral   \n",
       "3  doesn't contain lewd content  disagreement   \n",
       "4  doesn't contain lewd content         moral   \n",
       "\n",
       "                                     predicted_group  \\\n",
       "0                 the text directly references asian   \n",
       "1  ['it is unclear who is referenced', 'it is unc...   \n",
       "2                the text directly references muslim   \n",
       "3  ['the text indirectly references physical_dis'...   \n",
       "4                the text directly references jewish   \n",
       "\n",
       "                        stereotyping  intent  toxicity_ai  toxicity_human  \\\n",
       "0         uses positive stereotyping     5.0          5.0             5.0   \n",
       "1  doesn't use positive stereotyping     1.0          1.0             1.0   \n",
       "2  doesn't use positive stereotyping     5.0          5.0             5.0   \n",
       "3  doesn't use positive stereotyping     1.0          1.0             1.0   \n",
       "4  doesn't use positive stereotyping     5.0          5.0             5.0   \n",
       "\n",
       "  predicted_author actual_method  \n",
       "0            human          topk  \n",
       "1            human          topk  \n",
       "2            human          topk  \n",
       "3            human           cbs  \n",
       "4            human          topk  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(human_eval_big.shape)\n",
    "human_eval_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in text:\n",
      "text\n",
      "asians are trying to take over the world with their karate skills                                                                                  1\n",
      "if you want to get a good job, you have to have a good education, and if you want to get a good education, you have to                             1\n",
      "every time i see, a latina walking down the street (one who will have sex with me) i yell \"i hate u lesbians!\" -                                   1\n",
      "if i see you in public, i will call the police on you because i think you are a terrorist -\" i will call the police on                             1\n",
      "When you have 2 tabs open, it is called multitasking, when you have more than 3 it's called SUPER WOMAN.\\ncredits The                              1\n",
      "                                                                                                                                                  ..\n",
      "jewish puns can be really irritating, i'm not a jew and i find them annoying                                                                       1\n",
      "Racism is most likely the most common game plan of the holy book of jews                                                                           1\n",
      "native indians are always drunken, drug addicted rapists (falling into that good-natured, though perhaps slightly childlike, savage stereotype)    1\n",
      "in iran you find the highest mountains of the continent                                                                                            1\n",
      "we are the ones who came to this country and made it our home. we didnt come begging for a hand out and we sure didnt come here just               1\n",
      "Name: count, Length: 8960, dtype: int64\n",
      "\n",
      "Unique values in target_group:\n",
      "target_group\n",
      "women              717\n",
      "lgbtq              714\n",
      "mental_dis         714\n",
      "black              713\n",
      "chinese            706\n",
      "asian              702\n",
      "native_american    702\n",
      "middle_east        697\n",
      "muslim             688\n",
      "physical_dis       685\n",
      "mexican            684\n",
      "jewish             684\n",
      "latino             554\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in factual?:\n",
      "factual?\n",
      "neither factual nor opinion    4873\n",
      "opinion                        1539\n",
      "factual                        1308\n",
      "disagreement                   1183\n",
      "both factual and opinion         57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in ingroup_effect:\n",
      "ingroup_effect\n",
      "doesn't use in-group language         8785\n",
      "harmless due to in-group                84\n",
      "disagreement                            73\n",
      "harmful despite in-group                11\n",
      "maybe less harmful due to in-group       7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in lewd:\n",
      "lewd\n",
      "doesn't contain lewd content    8814\n",
      "contains lewd content            100\n",
      "disagreement                      31\n",
      "might contain lewd content        15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in framing:\n",
      "framing\n",
      "disagreement             4047\n",
      "moral                    1898\n",
      "                         1649\n",
      "cause                     677\n",
      "solution                  660\n",
      "positive stereotyping      27\n",
      "personal experience         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in predicted_group:\n",
      "predicted_group\n",
      "it is unclear who is referenced                                                                                                1745\n",
      "the text directly references mental_dis                                                                                         338\n",
      "the text directly references physical_dis                                                                                       295\n",
      "the text directly references jewish                                                                                             287\n",
      "the text directly references women                                                                                              258\n",
      "                                                                                                                               ... \n",
      "['the text references mentally disabled people', 'the text directly references mexican', 'it is unclear who is referenced']       1\n",
      "['the text references asians/whites', 'the text references asians, whites', 'the text references whites, asians']                 1\n",
      "['the text indirectly references black', 'the text references white women feminists', 'the text references white feminist']       1\n",
      "['the text references chinese', 'the text directly references latino', 'the text references chinese']                             1\n",
      "['the text references white', 'the text references whites', 'the text references white folks']                                    1\n",
      "Name: count, Length: 1476, dtype: int64\n",
      "\n",
      "Unique values in stereotyping:\n",
      "stereotyping\n",
      "doesn't use positive stereotyping    8455\n",
      "uses positive stereotyping            206\n",
      "disagreement                          170\n",
      "maybe uses positive stereotyping      129\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in intent:\n",
      "intent\n",
      "1.000000    2678\n",
      "1.666667     985\n",
      "1.333333     802\n",
      "5.000000     771\n",
      "2.333333     531\n",
      "2.000000     528\n",
      "4.333333     423\n",
      "3.666667     397\n",
      "4.666667     388\n",
      "3.000000     385\n",
      "2.666667     366\n",
      "3.333333     361\n",
      "4.000000     345\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in toxicity_ai:\n",
      "toxicity_ai\n",
      "1.000000    2398\n",
      "1.666667     957\n",
      "1.333333     918\n",
      "5.000000     866\n",
      "2.000000     551\n",
      "4.333333     492\n",
      "2.333333     488\n",
      "4.666667     471\n",
      "3.000000     392\n",
      "3.666667     387\n",
      "2.666667     382\n",
      "3.333333     347\n",
      "4.000000     311\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in toxicity_human:\n",
      "toxicity_human\n",
      "1.000000    2359\n",
      "5.000000    1007\n",
      "1.666667     946\n",
      "1.333333     871\n",
      "2.000000     526\n",
      "4.666667     520\n",
      "2.333333     493\n",
      "4.333333     469\n",
      "2.666667     382\n",
      "3.000000     368\n",
      "3.666667     365\n",
      "3.333333     343\n",
      "4.000000     311\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in predicted_author:\n",
      "predicted_author\n",
      "human    8038\n",
      "ai        922\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique values in actual_method:\n",
      "actual_method\n",
      "topk    4561\n",
      "cbs     4399\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in human_eval_big.columns:\n",
    "    print(f\"\\nUnique values in {col}:\")\n",
    "    print(human_eval_big[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on human annotated eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8960, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_group</th>\n",
       "      <th>factual?</th>\n",
       "      <th>ingroup_effect</th>\n",
       "      <th>lewd</th>\n",
       "      <th>framing</th>\n",
       "      <th>predicted_group</th>\n",
       "      <th>stereotyping</th>\n",
       "      <th>intent</th>\n",
       "      <th>toxicity_ai</th>\n",
       "      <th>toxicity_human</th>\n",
       "      <th>predicted_author</th>\n",
       "      <th>actual_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asians are trying to take over the world with ...</td>\n",
       "      <td>asian</td>\n",
       "      <td>opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>the text directly references asian</td>\n",
       "      <td>uses positive stereotyping</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have never seen a hotter lineup in my life t...</td>\n",
       "      <td>mexican</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td></td>\n",
       "      <td>['it is unclear who is referenced', 'it is unc...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muslims deseve to die</td>\n",
       "      <td>muslim</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>moral</td>\n",
       "      <td>the text directly references muslim</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people who are deaf or hard of hearing should ...</td>\n",
       "      <td>physical_dis</td>\n",
       "      <td>opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>['the text indirectly references physical_dis'...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>human</td>\n",
       "      <td>cbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jews were all bad people because they're in th...</td>\n",
       "      <td>jewish</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>moral</td>\n",
       "      <td>the text directly references jewish</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target_group  \\\n",
       "0  asians are trying to take over the world with ...         asian   \n",
       "1  i have never seen a hotter lineup in my life t...       mexican   \n",
       "2                              muslims deseve to die        muslim   \n",
       "3  people who are deaf or hard of hearing should ...  physical_dis   \n",
       "4  Jews were all bad people because they're in th...        jewish   \n",
       "\n",
       "                      factual?                 ingroup_effect  \\\n",
       "0                      opinion  doesn't use in-group language   \n",
       "1  neither factual nor opinion  doesn't use in-group language   \n",
       "2  neither factual nor opinion  doesn't use in-group language   \n",
       "3                      opinion  doesn't use in-group language   \n",
       "4                 disagreement  doesn't use in-group language   \n",
       "\n",
       "                           lewd       framing  \\\n",
       "0  doesn't contain lewd content  disagreement   \n",
       "1  doesn't contain lewd content                 \n",
       "2  doesn't contain lewd content         moral   \n",
       "3  doesn't contain lewd content  disagreement   \n",
       "4  doesn't contain lewd content         moral   \n",
       "\n",
       "                                     predicted_group  \\\n",
       "0                 the text directly references asian   \n",
       "1  ['it is unclear who is referenced', 'it is unc...   \n",
       "2                the text directly references muslim   \n",
       "3  ['the text indirectly references physical_dis'...   \n",
       "4                the text directly references jewish   \n",
       "\n",
       "                        stereotyping  intent  toxicity_ai  toxicity_human  \\\n",
       "0         uses positive stereotyping     5.0          5.0             5.0   \n",
       "1  doesn't use positive stereotyping     1.0          1.0             1.0   \n",
       "2  doesn't use positive stereotyping     5.0          5.0             5.0   \n",
       "3  doesn't use positive stereotyping     1.0          1.0             1.0   \n",
       "4  doesn't use positive stereotyping     5.0          5.0             5.0   \n",
       "\n",
       "  predicted_author actual_method  \n",
       "0            human          topk  \n",
       "1            human          topk  \n",
       "2            human          topk  \n",
       "3            human           cbs  \n",
       "4            human          topk  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(human_eval_small.shape)\n",
    "human_eval_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Validating Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "print(\"labels:\", labels)\n",
    "\n",
    "# Create a mapping from label to index\n",
    "label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Create a reverse mapping from index to label\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "\n",
    "print(\"label2idx:\", label2idx)\n",
    "print(\"idx2label:\", idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
